{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "from skbio.stats.ordination import pcoa\n",
    "from skbio.stats.distance import permanova, DistanceMatrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def preprocess_and_pca(file_path, n_components=15):\n",
    "    # Read the Excel file\n",
    "    data = pd.read_excel(file_path, header=None)\n",
    "    \n",
    "    # Ignore the first row, the first column, and the last 3 columns\n",
    "    data = data.iloc[1:, 1:-3]\n",
    "    \n",
    "    # Convert any non-numeric values to NaN\n",
    "    data = data.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Impute NaN values with the mean of each column\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    data_imputed = imputer.fit_transform(data)\n",
    "    \n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data_imputed)\n",
    "    \n",
    "    # Perform PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    principal_components = pca.fit_transform(scaled_data)\n",
    "    \n",
    "    # Create a DataFrame for the principal components\n",
    "    columns = [f\"PC{i+1}\" for i in range(n_components)]\n",
    "    pca_df = pd.DataFrame(data=principal_components, columns=columns)\n",
    "    \n",
    "    return pca_df, pca, scaler\n",
    "\n",
    "# Paths to your datasets\n",
    "hv_w_file_path = \"Desktop/HV_Dataset.xlsx\"\n",
    "cc_w_file_path = \"Desktop/CC_Dataset.xlsx\"\n",
    "\n",
    "# Number of PCA components\n",
    "n_components = 15\n",
    "\n",
    "# Preprocess and perform PCA\n",
    "HV_w_df, hv_w_pca, hv_w_scaler = preprocess_and_pca(hv_w_file_path, n_components)\n",
    "CC_w_df, cc_w_pca, cc_w_scaler = preprocess_and_pca(cc_w_file_path, n_components)\n",
    "\n",
    "# Add labels to the DataFrames\n",
    "HV_w_df['label'] = 0  # 0 for healthy patients\n",
    "CC_w_df['label'] = 1  # 1 for cancer patients\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "merged_df = pd.concat([HV_w_df, CC_w_df], axis=0)\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = merged_df.drop(columns='label')\n",
    "y = merged_df['label']\n",
    "\n",
    "# Split into 80% training and 20% test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize XGBoost and SVM models\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, n_estimators=100, max_depth=5)\n",
    "svm_model = SVC(probability=True, random_state=42, C=1.0, kernel='rbf')  # SVM with RBF kernel\n",
    "\n",
    "# Perform cross-validation with XGBoost and SVM on the training set\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "xgb_cv_predictions_proba = cross_val_predict(xgb_model, X_train, y_train, cv=cv, method='predict_proba')[:, 1]\n",
    "svm_cv_predictions_proba = cross_val_predict(svm_model, X_train, y_train, cv=cv, method='predict_proba')[:, 1]\n",
    "\n",
    "# Ensemble predictions using simple averaging for training set\n",
    "y_train_pred_ensemble_proba = (xgb_cv_predictions_proba + svm_cv_predictions_proba) / 2\n",
    "y_train_pred_ensemble = (y_train_pred_ensemble_proba > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the ensemble model on the training set\n",
    "accuracy_ensemble_train = accuracy_score(y_train, y_train_pred_ensemble)\n",
    "precision_ensemble_train = precision_score(y_train, y_train_pred_ensemble)\n",
    "recall_ensemble_train = recall_score(y_train, y_train_pred_ensemble)\n",
    "f1_ensemble_train = f1_score(y_train, y_train_pred_ensemble)\n",
    "auc_ensemble_train = roc_auc_score(y_train, y_train_pred_ensemble_proba)\n",
    "\n",
    "print(\"\\nEnsemble Model Performance on Training Set:\")\n",
    "print(\"Accuracy:\", accuracy_ensemble_train)\n",
    "print(\"Precision:\", precision_ensemble_train)\n",
    "print(\"Recall:\", recall_ensemble_train)\n",
    "print(\"F1 Score:\", f1_ensemble_train)\n",
    "print(\"AUC:\", auc_ensemble_train)\n",
    "\n",
    "# Fit the models on the entire training set\n",
    "xgb_model.fit(X_train, y_train)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set using the fitted models\n",
    "xgb_test_predictions_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "svm_test_predictions_proba = svm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Ensemble predictions using simple averaging for test set\n",
    "y_test_pred_ensemble_proba = (xgb_test_predictions_proba + svm_test_predictions_proba) / 2\n",
    "y_test_pred_ensemble = (y_test_pred_ensemble_proba > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the ensemble model on the test set\n",
    "accuracy_ensemble_test = accuracy_score(y_test, y_test_pred_ensemble)\n",
    "precision_ensemble_test = precision_score(y_test, y_test_pred_ensemble)\n",
    "recall_ensemble_test = recall_score(y_test, y_test_pred_ensemble)\n",
    "f1_ensemble_test = f1_score(y_test, y_test_pred_ensemble)\n",
    "auc_ensemble_test = roc_auc_score(y_test, y_test_pred_ensemble_proba)\n",
    "\n",
    "print(\"\\nEnsemble Model Performance on Test Set:\")\n",
    "print(\"Accuracy:\", accuracy_ensemble_test)\n",
    "print(\"Precision:\", precision_ensemble_test)\n",
    "print(\"Recall:\", recall_ensemble_test)\n",
    "print(\"F1 Score:\", f1_ensemble_test)\n",
    "print(\"AUC:\", auc_ensemble_test)\n",
    "\n",
    "# Combine datasets for beta diversity calculation\n",
    "combined_data = pd.concat([HV_w_df.drop(columns='label'), CC_w_df.drop(columns='label')], axis=0)\n",
    "\n",
    "# Calculate Bray-Curtis dissimilarity matrix\n",
    "bray_curtis_matrix = pairwise_distances(combined_data, metric='braycurtis')\n",
    "\n",
    "print(\"\\nBray-Curtis Dissimilarity Matrix:\")\n",
    "print(pd.DataFrame(bray_curtis_matrix))\n",
    "\n",
    "# Perform PERMANOVA\n",
    "grouping_labels = np.concatenate([np.zeros(len(HV_w_df)), np.ones(len(CC_w_df))])  # Create grouping labels\n",
    "grouping_labels_str = grouping_labels.astype(str)  # Convert labels to string for PERMANOVA\n",
    "distance_matrix = DistanceMatrix(bray_curtis_matrix)  # Create DistanceMatrix object\n",
    "\n",
    "permanova_results = permanova(distance_matrix, grouping_labels_str)\n",
    "print(\"\\nPERMANOVA Results:\")\n",
    "print(permanova_results)\n",
    "\n",
    "# Calculate Beta Diversity (Bray-Curtis dissimilarity)\n",
    "beta_diversity_healthy = bray_curtis_matrix[:len(HV_w_df), :len(HV_w_df)].mean()\n",
    "beta_diversity_cancer = bray_curtis_matrix[len(HV_w_df):, len(HV_w_df):].mean()\n",
    "beta_diversity_between_groups = bray_curtis_matrix[:len(HV_w_df), len(HV_w_df):].mean()\n",
    "\n",
    "print(\"\\nBeta Diversity for Healthy Patients:\", beta_diversity_healthy)\n",
    "print(\"Beta Diversity for Cancer Patients:\", beta_diversity_cancer)\n",
    "print(\"Beta Diversity Between Healthy and Cancer Patients:\", beta_diversity_between_groups)\n",
    "\n",
    "# Perform PCoA\n",
    "pcoa_results = pcoa(bray_curtis_matrix)\n",
    "\n",
    "# Plot PCoA results\n",
    "def plot_pcoa(pcoa_results, labels):\n",
    "    # Extract the first two PCoA coordinates\n",
    "    pc1 = pcoa_results.samples['PC1']\n",
    "    pc2 = pcoa_results.samples['PC2']\n",
    "\n",
    "    # Create a scatter plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(pc1, pc2, c=labels, cmap='viridis', edgecolor='k', s=100, alpha=0.7)\n",
    "    plt.xlabel(f'PC1 ({pcoa_results.proportion_explained[0]*100:.2f}% of variance)')\n",
    "    plt.ylabel(f'PC2 ({pcoa_results.proportion_explained[1]*100:.2f}% of variance)')\n",
    "    plt.title('PCoA of Microbiome Data (Bray-Curtis Dissimilarity)')\n",
    "    plt.colorbar(scatter, ticks=[0, 1], label='Sample Label')\n",
    "    plt.clim(-0.5, 1.5)\n",
    "    plt.grid(False)  # Remove grid lines\n",
    "    plt.show()\n",
    "\n",
    "# Plot PCoA results with labels\n",
    "labels = np.concatenate([np.zeros(len(HV_w_df)), np.ones(len(CC_w_df))])\n",
    "plot_pcoa(pcoa_results, labels)\n",
    "\n",
    "# Plot ROC curves for training and test sets\n",
    "def plot_roc_curve(y_true, y_scores, title='ROC Curve'):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    auc = roc_auc_score(y_true, y_scores)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'AUC = {auc:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], color='grey', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# Plot ROC curve for training set\n",
    "plot_roc_curve(y_train, y_train_pred_ensemble_proba, title='ROC Curve - Training Set')\n",
    "\n",
    "# Plot ROC curve for test set\n",
    "plot_roc_curve(y_test, y_test_pred_ensemble_proba, title='ROC Curve - Test Set')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Paths to your datasets\n",
    "hv_file_path = \"Desktop/HV_Dataset.xlsx\"\n",
    "cc_file_path = \"Desktop/CC_Dataset.xlsx\"\n",
    "\n",
    "# Read the Excel files\n",
    "healthy_data = pd.read_excel(hv_file_path, index_col=False)\n",
    "cancer_data = pd.read_excel(cc_file_path, index_col=False)\n",
    "\n",
    "# Exclude the first column from the datasets\n",
    "healthy_data = healthy_data.iloc[:, 1:]\n",
    "cancer_data = cancer_data.iloc[:, 1:]\n",
    "\n",
    "# Function to compute Shannon diversity index and evenness for each patient\n",
    "def compute_diversity_and_evenness(data):\n",
    "    # Convert counts to proportions\n",
    "    proportions = data.div(data.sum(axis=0), axis=1)\n",
    "    # Compute Shannon diversity index\n",
    "    diversity = -np.sum(proportions * np.log(proportions), axis=0)\n",
    "    # Compute evenness\n",
    "    evenness = diversity / np.log(data.shape[0])\n",
    "    return diversity, evenness\n",
    "\n",
    "# Compute diversity and evenness for healthy patients\n",
    "healthy_diversity, healthy_evenness = compute_diversity_and_evenness(healthy_data)\n",
    "\n",
    "# Compute diversity and evenness for cancer patients\n",
    "cancer_diversity, cancer_evenness = compute_diversity_and_evenness(cancer_data)\n",
    "\n",
    "# Statistical significance testing\n",
    "diversity_stat, diversity_p = mannwhitneyu(healthy_diversity, cancer_diversity)\n",
    "evenness_stat, evenness_p = mannwhitneyu(healthy_evenness, cancer_evenness)\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "data = pd.DataFrame({\n",
    "    'Group': ['Healthy'] * len(healthy_diversity) + ['Cancer'] * len(cancer_diversity),\n",
    "    'Shannon Diversity': np.concatenate([healthy_diversity, cancer_diversity]),\n",
    "    'Evenness': np.concatenate([healthy_evenness, cancer_evenness])\n",
    "})\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(10, 8), gridspec_kw={'hspace': 0.3})\n",
    "\n",
    "# Box plot for Shannon Diversity Index\n",
    "axs[0].boxplot([healthy_diversity, cancer_diversity], labels=['Healthy', 'Cancer'])\n",
    "axs[0].set_ylabel('Shannon Diversity Index')\n",
    "axs[0].set_title('Shannon Diversity Index for Each Patient\\n(p = {:.3e})'.format(diversity_p))\n",
    "\n",
    "# Box plot for Evenness\n",
    "axs[1].boxplot([healthy_evenness, cancer_evenness], labels=['Healthy', 'Cancer'])\n",
    "axs[1].set_ylabel('Evenness')\n",
    "axs[1].set_title('Evenness for Each Patient\\n(p = {:.3e})'.format(evenness_p))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths to your datasets\n",
    "hv_file_path = \"Desktop/HV_Dataset.xlsx\"\n",
    "cc_file_path = \"Desktop/CC_Dataset.xlsx\"\n",
    "\n",
    "# Read the Excel files\n",
    "healthy_data = pd.read_excel(hv_file_path, index_col=False)\n",
    "cancer_data = pd.read_excel(cc_file_path, index_col=False)\n",
    "\n",
    "# Define a function to preprocess the data at the genus level\n",
    "def preprocess_genus_level(data):\n",
    "    # Group the data at the genus level (assuming first column is 'Microbiome at Genus Level')\n",
    "    genus_data = data.groupby(data.columns[0]).sum()\n",
    "    return genus_data\n",
    "\n",
    "# Preprocess the data at the genus level for both datasets\n",
    "healthy_genus_data = preprocess_genus_level(healthy_data)\n",
    "cancer_genus_data = preprocess_genus_level(cancer_data)\n",
    "\n",
    "# Compute the mean abundance and standard error for each genus across all patients\n",
    "mean_abundance_healthy = healthy_genus_data.mean(axis=1)\n",
    "mean_abundance_cancer = cancer_genus_data.mean(axis=1)\n",
    "\n",
    "# Compute the standard error\n",
    "std_error_healthy = healthy_genus_data.std(axis=1) / (len(healthy_genus_data.columns) ** 0.5)\n",
    "std_error_cancer = cancer_genus_data.std(axis=1) / (len(cancer_genus_data.columns) ** 0.5)\n",
    "\n",
    "# Find the top 5 genera with the highest differences in abundance between healthy and cancer datasets\n",
    "top_diff_genera = (mean_abundance_cancer - mean_abundance_healthy).nlargest(5)\n",
    "\n",
    "# Create a DataFrame to hold the abundance values for these top 5 genera\n",
    "top_genera_abundance = pd.DataFrame({\n",
    "    'Healthy': mean_abundance_healthy[top_diff_genera.index],\n",
    "    'Cancer': mean_abundance_cancer[top_diff_genera.index],\n",
    "    'Healthy_SE': std_error_healthy[top_diff_genera.index],\n",
    "    'Cancer_SE': std_error_cancer[top_diff_genera.index]\n",
    "})\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "bar_width = 0.35\n",
    "indices = range(len(top_genera_abundance))\n",
    "\n",
    "# Create bars for Healthy and Cancer with error bars\n",
    "bars1 = ax.bar([i - bar_width/2 for i in indices], top_genera_abundance['Healthy'], bar_width,\n",
    "               label='Healthy', color='skyblue', yerr=top_genera_abundance['Healthy_SE'], capsize=5)\n",
    "bars2 = ax.bar([i + bar_width/2 for i in indices], top_genera_abundance['Cancer'], bar_width,\n",
    "               label='Cancer', color='salmon', yerr=top_genera_abundance['Cancer_SE'], capsize=5)\n",
    "\n",
    "# Adding labels\n",
    "ax.set_xlabel('Genus')\n",
    "ax.set_ylabel('Mean Abundance')\n",
    "ax.set_title('Comparison of Top 5 Genera with Highest Differences in Abundance')\n",
    "ax.set_xticks(indices)\n",
    "ax.set_xticklabels(top_genera_abundance.index, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths to your datasets\n",
    "hv_file_path = \"Desktop/HV_Dataset.xlsx\"\n",
    "cc_file_path = \"Desktop/CC_Dataset.xlsx\"\n",
    "\n",
    "# Read the Excel files\n",
    "healthy_data = pd.read_excel(hv_file_path, index_col=False)\n",
    "cancer_data = pd.read_excel(cc_file_path, index_col=False)\n",
    "\n",
    "# Function to compute average abundance across all patients\n",
    "def compute_average_abundance(data):\n",
    "    data = data.iloc[:, 1:]  # Ignore the first column (assumed to be labels)\n",
    "    # Compute mean abundance for each microbiome across all patients\n",
    "    mean_abundance = data.mean(axis=1)\n",
    "    # Sort by abundance and select top 15\n",
    "    mean_abundance_top15 = mean_abundance.sort_values(ascending=False).head(15)\n",
    "    return mean_abundance_top15\n",
    "\n",
    "# Compute average abundance for healthy and cancer patients\n",
    "healthy_mean_abundance_top15 = compute_average_abundance(healthy_data)\n",
    "cancer_mean_abundance_top15 = compute_average_abundance(cancer_data)\n",
    "\n",
    "# Extract labels from the first column of the original data\n",
    "healthy_labels = healthy_data.iloc[healthy_mean_abundance_top15.index, 0].values\n",
    "cancer_labels = cancer_data.iloc[cancer_mean_abundance_top15.index, 0].values\n",
    "\n",
    "# Combine the top labels from both datasets\n",
    "top_labels = list(set(healthy_labels).union(set(cancer_labels)))\n",
    "\n",
    "# Create a DataFrame for the combined top labels\n",
    "combined_abundance = pd.DataFrame(index=top_labels)\n",
    "\n",
    "# Fill in the abundance values, setting missing values to 0\n",
    "combined_abundance['Healthy'] = healthy_data.set_index(healthy_data.columns[0]).reindex(top_labels).mean(axis=1).fillna(0)\n",
    "combined_abundance['Cancer'] = cancer_data.set_index(cancer_data.columns[0]).reindex(top_labels).mean(axis=1).fillna(0)\n",
    "\n",
    "# Normalize the abundances to sum up to 1 for each group\n",
    "combined_abundance['Healthy'] = combined_abundance['Healthy'] / combined_abundance['Healthy'].sum()\n",
    "combined_abundance['Cancer'] = combined_abundance['Cancer'] / combined_abundance['Cancer'].sum()\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "bar_width = 0.6\n",
    "indices = range(len(combined_abundance.columns))\n",
    "\n",
    "# Create stacked bars\n",
    "bars = []\n",
    "colors = plt.cm.tab20.colors  # Using a colormap for distinct colors\n",
    "for i, bacteria in enumerate(combined_abundance.index):\n",
    "    if i == 0:\n",
    "        bars.append(ax.bar(indices, combined_abundance.loc[bacteria], bar_width, label=bacteria, color=colors[i % len(colors)]))\n",
    "    else:\n",
    "        bars.append(ax.bar(indices, combined_abundance.loc[bacteria], bar_width, bottom=combined_abundance.iloc[:i].sum(), label=bacteria, color=colors[i % len(colors)]))\n",
    "\n",
    "# Adding labels\n",
    "ax.set_xlabel('Group')\n",
    "ax.set_ylabel('Relative Abundance')\n",
    "ax.set_title('Top Abundant Bacteria in Healthy and Cancer Patients')\n",
    "ax.set_xticks(indices)\n",
    "ax.set_xticklabels(['Healthy', 'Cancer'])\n",
    "ax.legend(title='Bacteria', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
